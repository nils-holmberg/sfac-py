{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsi_0WbN__Nt"
   },
   "source": [
    "[home](https://nils-holmberg.github.io/sfac-py/web/210928-nlp/)\n",
    "\n",
    "# day 2: getting started with nlp\n",
    "- overview day 2\n",
    "\n",
    "|time  |section |concepts               |outcomes                               |\n",
    "|:-----|:-------|:----------------------|:--------------------------------------|\n",
    "|09-10 |2.1.1   |[spacy](01-intro.html) |install spacy package to anaconda venv |\n",
    "|      |2.1.2   |import text            |                                       |\n",
    "|      |2.1.3   |create document        |                                       |\n",
    "|      |break   |                       |                                       |\n",
    "|10-11 |2.2.1   |clean                  |                                       |\n",
    "|      |2.2.2   |tokenize               |                                       |\n",
    "|      |2.2.3   |ner                    |                                       |\n",
    "|      |break   |                       |                                       |\n",
    "|11-12 |2.3.1   |classify               |                                       |\n",
    "|      |2.3.2   |                       |                                       |\n",
    "|      |2.3.3   |                       |                                       |\n",
    "|12-13 |lunch   |                       |                                       |\n",
    "\n",
    "- section 2.1.1 python syntax\n",
    "    - [variables and data types](#variables)\n",
    "- section 2.1.2 functions\n",
    "    - [functions and modules](#functions)\n",
    "- section 2.1.3 files\n",
    "    - [files and directories](#files)\n",
    "\n",
    "# section 2.1.1\n",
    "- check, update anaconda installation, create nlp venv\n",
    "\n",
    "```python\n",
    "# update anaconda, env packages\n",
    "conda update anaconda\n",
    "conda update --all\n",
    "# install spacy nlp package\n",
    "conda install -c conda-forge -n base spacy\n",
    "# get trained pipline, language model\n",
    "python -m spacy download en_core_web_sm\n",
    "# start jupyter notebook\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "# section 2.1.2\n",
    "- some text\n",
    "\n",
    "# section 2.1.3\n",
    "- some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy Features \n",
    "\n",
    "In the documentation, you'll come across mentions of spaCy's features and\n",
    "capabilities. Some of them refer to linguistic concepts, while others are\n",
    "related to more general machine learning functionality.\n",
    "\n",
    "| Name                                  | Description                                                                                                        |\n",
    "| ------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Tokenization**                      | Segmenting text into words, punctuations marks etc.                                                                |\n",
    "| **Part-of-speech** (POS) **Tagging**  | Assigning word types to tokens, like verb or noun.                                                                 |\n",
    "| **Dependency Parsing**                | Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object. |\n",
    "| **Lemmatization**                     | Assigning the base forms of words. For example, the lemma of \"was\" is \"be\", and the lemma of \"rats\" is \"rat\".      |\n",
    "| **Sentence Boundary Detection** (SBD) | Finding and segmenting individual sentences.                                                                       |\n",
    "| **Named Entity Recognition** (NER)    | Labelling named \"real-world\" objects, like persons, companies or locations.                                        |\n",
    "| **Entity Linking** (EL)               | Disambiguating textual entities to unique identifiers in a knowledge base.                                         |\n",
    "| **Similarity**                        | Comparing words, text spans and documents and how similar they are to each other.                                  |\n",
    "| **Text Classification**               | Assigning categories or labels to a whole document, or parts of a document.                                        |\n",
    "| **Rule-based Matching**               | Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.       |\n",
    "| **Training**                          | Updating and improving a statistical model's predictions.                                                          |\n",
    "| **Serialization**                     | Saving objects to files or byte strings.                                                                           |\n",
    "\n",
    "### Tokenization\n",
    "First, the raw text is split on whitespace characters, similar to\n",
    "`text.split(' ')`. Then, the tokenizer processes the text from left to right. On\n",
    "each substring, it performs two checks:\n",
    "\n",
    "1. **Does the substring match a tokenizer exception rule?** For example, \"don't\"\n",
    "   does not contain whitespace, but should be split into two tokens, \"do\" and\n",
    "   \"n't\", while \"U.K.\" should always remain one token.\n",
    "\n",
    "2. **Can a prefix, suffix or infix be split off?** For example punctuation like\n",
    "   commas, periods, hyphens or quotes.\n",
    "\n",
    "If there's a match, the rule is applied and the tokenizer continues its loop,\n",
    "starting with the newly split substrings. This way, spaCy can split **complex,\n",
    "nested tokens** like combinations of abbreviations and multiple punctuation\n",
    "marks.\n",
    "\n",
    "|   0   |  1  |    2    |  3  |   4    |  5   |    6    |  7  |  8  |  9  |   10    |\n",
    "| :---: | :-: | :-----: | :-: | :----: | :--: | :-----: | :-: | :-: | :-: | :-----: |\n",
    "| Apple | is  | looking | at  | buying | U.K. | startup | for | \\$  |  1  | billion |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguistic annotations\n",
    "\n",
    "spaCy provides a variety of linguistic annotations to give you **insights into a\n",
    "text's grammatical structure**. This includes the word types, like the parts of\n",
    "speech, and how the words are related to each other. For example, if you're\n",
    "analyzing text, it makes a huge difference whether a noun is the subject of a\n",
    "sentence, or the object â€“ or whether \"google\" is used as a verb, or refers to\n",
    "the website or company in a specific context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "53ukTwP4__OE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech tags and dependencies\n",
    "\n",
    "After tokenization, spaCy can **parse** and **tag** a given `Doc`. This is where\n",
    "the trained pipeline and its statistical models come in, which enable spaCy to\n",
    "**make predictions** of which tag or label most likely applies in this context.\n",
    "A trained component includes binary data that is produced by showing a system\n",
    "enough examples for it to make predictions that generalize across the language â€“\n",
    "for example, a word following \"the\" in English is most likely a noun.\n",
    "\n",
    "Linguistic annotations are available as\n",
    "[`Token` attributes](/api/token#attributes). Like many NLP libraries, spaCy\n",
    "**encodes all strings to hash values** to reduce memory usage and improve\n",
    "efficiency. So to get the readable string representation of an attribute, we\n",
    "need to add an underscore `_` to its name:\n",
    "\n",
    "To learn more about **part-of-speech tagging** and rule-based morphology, and\n",
    "how to **navigate and use the parse tree** effectively, see the usage guides on\n",
    "[part-of-speech tagging](/usage/linguistic-features#pos-tagging) and\n",
    "[using the dependency parse](/usage/linguistic-features#dependency-parse).\n",
    "\n",
    "> - **Text:** The original word text.\n",
    "> - **Lemma:** The base form of the word.\n",
    "> - **POS:** The simple [UPOS](https://universaldependencies.org/docs/u/pos/)\n",
    ">   part-of-speech tag.\n",
    "> - **Tag:** The detailed part-of-speech tag.\n",
    "> - **Dep:** Syntactic dependency, i.e. the relation between tokens.\n",
    "> - **Shape:** The word shape â€“ capitalization, punctuation, digits.\n",
    "> - **is alpha:** Is the token an alpha character?\n",
    "> - **is stop:** Is the token part of a stop list, i.e. the most common words of\n",
    ">   the language?\n",
    "\n",
    "| Text    | Lemma   | POS     | Tag   | Dep        | Shape   | alpha   | stop    |\n",
    "| ------- | ------- | ------- | ----- | ---------- | ------- | ------- | ------- |\n",
    "| Apple   | apple   | `PROPN` | `NNP` | `nsubj`    | `Xxxxx` | `True`  | `False` |\n",
    "| is      | be      | `AUX`   | `VBZ` | `aux`      | `xx`    | `True`  | `True`  |\n",
    "| looking | look    | `VERB`  | `VBG` | `ROOT`     | `xxxx`  | `True`  | `False` |\n",
    "| at      | at      | `ADP`   | `IN`  | `prep`     | `xx`    | `True`  | `True`  |\n",
    "| buying  | buy     | `VERB`  | `VBG` | `pcomp`    | `xxxx`  | `True`  | `False` |\n",
    "| U.K.    | u.k.    | `PROPN` | `NNP` | `compound` | `X.X.`  | `False` | `False` |\n",
    "| startup | startup | `NOUN`  | `NN`  | `dobj`     | `xxxx`  | `True`  | `False` |\n",
    "| for     | for     | `ADP`   | `IN`  | `prep`     | `xxx`   | `True`  | `True`  |\n",
    "| \\$      | \\$      | `SYM`   | `$`   | `quantmod` | `$`     | `False` | `False` |\n",
    "| 1       | 1       | `NUM`   | `CD`  | `compound` | `d`     | `False` | `False` |\n",
    "| billion | billion | `NUM`   | `CD`  | `pobj`     | `xxxx`  | `True`  | `False` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"acc063eba04843e289d37263ce427c92-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-acc063eba04843e289d37263ce427c92-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-acc063eba04843e289d37263ce427c92-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entities \n",
    "\n",
    "To learn more about entity recognition in spaCy, how to **add your own\n",
    "entities** to a document and how to **train and update** the entity predictions\n",
    "of a model, see the usage guides on\n",
    "[named entity recognition](/usage/linguistic-features#named-entities) and\n",
    "[training pipelines](/usage/training).\n",
    "\n",
    "A named entity is a \"real-world object\" that's assigned a name â€“ for example, a\n",
    "person, a country, a product or a book title. spaCy can **recognize various\n",
    "types of named entities in a document, by asking the model for a\n",
    "prediction**. Because models are statistical and strongly depend on the\n",
    "examples they were trained on, this doesn't always work _perfectly_ and might\n",
    "need some tuning later, depending on your use case.\n",
    "\n",
    "Named entities are available as the `ents` property of a `Doc`:\n",
    "\n",
    "> - **Text:** The original entity text.\n",
    "> - **Start:** Index of start of entity in the `Doc`.\n",
    "> - **End:** Index of end of entity in the `Doc`.\n",
    "> - **Label:** Entity label, i.e. type.\n",
    "\n",
    "| Text        | Start | End | Label   | Description                                          |\n",
    "| ----------- | :---: | :-: | ------- | ---------------------------------------------------- |\n",
    "| Apple       |   0   |  5  | `ORG`   | Companies, agencies, institutions.                   |\n",
    "| U.K.        |  27   | 31  | `GPE`   | Geopolitical entity, i.e. countries, cities, states. |\n",
    "| \\$1 billion |  44   | 54  | `MONEY` | Monetary values, including unit.                     |\n",
    "\n",
    "Using spaCy's built-in [displaCy visualizer](/usage/visualizers), here's what\n",
    "our example sentence and its named entities look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors and similarity \n",
    "\n",
    "To learn more about word vectors, how to **customize them** and how to load\n",
    "**your own vectors** into spaCy, see the usage guide on\n",
    "[using word vectors and semantic similarities](/usage/linguistic-features#vectors-similarity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:conda-nlp]",
   "language": "python",
   "name": "conda-env-conda-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
